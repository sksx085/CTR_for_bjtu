{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "# ----------------导入库-----------------\n",
    "# 数据探索模块使用第三方库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import *\n",
    "# 核心模型使用第三方库\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# 交叉验证所使用的第三方库\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "# 评估指标所使用的的第三方库\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "# 忽略报警所使用的第三方库\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 禁止hash随机化\n",
    "set_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------数据预处理-------------\n",
    "# 读取训练数据和测试数据\n",
    "# 读取训练数据和测试数据\n",
    "train_data_ads = pd.read_csv('train\\\\train_data_ads.csv')\n",
    "train_data_feeds = pd.read_csv('train\\\\train_feeds.csv')\n",
    "\n",
    "test_data_ads = pd.read_csv('test\\\\test_data_ads.csv')\n",
    "test_data_feeds = pd.read_csv('test\\\\test_feeds.csv')\n",
    "\n",
    "# 合并数据\n",
    "train_data_ads['istest'] = 0\n",
    "test_data_ads['istest'] = 1\n",
    "data_ads = pd.concat([train_data_ads, test_data_ads], axis=0, ignore_index=True)\n",
    "\n",
    "train_data_feeds['istest'] = 0\n",
    "test_data_feeds['istest'] = 1\n",
    "data_feeds = pd.concat([train_data_feeds, test_data_feeds], axis=0, ignore_index=True)\n",
    "\n",
    "del train_data_ads, test_data_ads, train_data_feeds, test_data_feeds\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique属性数统计特征 Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:17<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique属性数统计特征 Ending...\n",
      "mean均值统计特征 Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean均值统计特征 Ending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------特征工程---------------\n",
    "# 包含自然数编码、特征提取和内存压缩三部分内容。\n",
    "# 1、自然数编码\n",
    "def label_encode(series, series2):\n",
    "    unique = list(series.unique())\n",
    "    return series2.map(dict(zip(\n",
    "        unique, range(series.nunique())\n",
    "    )))\n",
    "\n",
    "\n",
    "for col in ['ad_click_list_v001', 'ad_click_list_v002', 'ad_click_list_v003', 'ad_close_list_v001',\n",
    "            'ad_close_list_v002', 'ad_close_list_v003', 'u_newsCatInterestsST']:\n",
    "    data_ads[col] = label_encode(data_ads[col], data_ads[col])\n",
    "\n",
    "# 2、特征提取\n",
    "# data_feeds特征构建\n",
    "# 特征提取部分围绕着data_feeds进行构建（添加源域信息）\n",
    "# 主要是nunique属性数统计和mean均值统计。\n",
    "# 由于是baseline方案，所以整体的提取比较粗暴，大家还是有很多的优化空间。\n",
    "\n",
    "\n",
    "# -------------------------------1. nunique属性数统计特征-------------------------------------------\n",
    "print('nunique属性数统计特征 Starting...')\n",
    "cols = [f for f in data_feeds.columns if f not in ['label', 'istest', 'u_userId']]\n",
    "for col in tqdm(cols):\n",
    "    tmp = data_feeds.groupby(['u_userId'])[col].nunique().reset_index()\n",
    "    tmp.columns = ['user_id', col + '_feeds_nuni']\n",
    "    data_ads = data_ads.merge(tmp, on='user_id', how='left')\n",
    "print('nunique属性数统计特征 Ending...')\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------2. mean均值统计特征------------------------------------------------\n",
    "print('mean均值统计特征 Starting...')\n",
    "cols = [f for f in data_feeds.columns if\n",
    "        f not in ['istest', 'u_userId', 'u_newsCatInterests', 'u_newsCatDislike', 'u_newsCatInterestsST',\n",
    "                  'u_click_ca2_news', 'i_docId', 'i_s_sourceId', 'i_entities']]\n",
    "for col in tqdm(cols):\n",
    "    tmp = data_feeds.groupby(['u_userId'])[col].mean().reset_index()\n",
    "    tmp.columns = ['user_id', col + '_feeds_mean']\n",
    "    data_ads = data_ads.merge(tmp, on='user_id', how='left')\n",
    "print('mean均值统计特征 Ending...')\n",
    "# -------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\ML\\XGboost\\XGboost2.ipynb 单元格 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data_ads[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ads[\u001b[39m'\u001b[39m\u001b[39mpt_d\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(\u001b[39mstr\u001b[39m(x)[\u001b[39m4\u001b[39m:\u001b[39m6\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data_ads[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ads[\u001b[39m'\u001b[39m\u001b[39mpt_d\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(\u001b[39mstr\u001b[39m(x)[\u001b[39m6\u001b[39m:\u001b[39m8\u001b[39m]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data_ads[\u001b[39m'\u001b[39m\u001b[39mhour\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ads[\u001b[39m'\u001b[39;49m\u001b[39mpt_d\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mint\u001b[39;49m(\u001b[39mstr\u001b[39;49m(x)[\u001b[39m8\u001b[39;49m:\u001b[39m10\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# data_ads['minu'] = data_ads['pt_d'].apply(lambda x: int(str(x)[10:12]))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# data_ads['date'] = data_ads['day']*1440 + data_ads['hour']*60 + data_ads['minu']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_date_feature\u001b[39m(data, gap_list\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m], col\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[1;32me:\\anaconda\\Lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4755\u001b[0m         func,\n\u001b[0;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32me:\\anaconda\\Lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32me:\\anaconda\\Lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1289\u001b[0m )\n\u001b[0;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32me:\\anaconda\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32me:\\anaconda\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mg:\\ML\\XGboost\\XGboost2.ipynb 单元格 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data_ads[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ads[\u001b[39m'\u001b[39m\u001b[39mpt_d\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(\u001b[39mstr\u001b[39m(x)[\u001b[39m4\u001b[39m:\u001b[39m6\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data_ads[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ads[\u001b[39m'\u001b[39m\u001b[39mpt_d\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(\u001b[39mstr\u001b[39m(x)[\u001b[39m6\u001b[39m:\u001b[39m8\u001b[39m]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data_ads[\u001b[39m'\u001b[39m\u001b[39mhour\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ads[\u001b[39m'\u001b[39m\u001b[39mpt_d\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39;49m(\u001b[39mstr\u001b[39;49m(x)[\u001b[39m8\u001b[39;49m:\u001b[39m10\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# data_ads['minu'] = data_ads['pt_d'].apply(lambda x: int(str(x)[10:12]))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# data_ads['date'] = data_ads['day']*1440 + data_ads['hour']*60 + data_ads['minu']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/ML/XGboost/XGboost2.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_date_feature\u001b[39m(data, gap_list\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m], col\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# -------------------------------3. 穿越特征------------------------------------------------\n",
    "# print('穿越特征 Starting...')\n",
    "data_ads['month'] = data_ads['pt_d'].apply(lambda x: int(str(x)[4:6]))\n",
    "data_ads['day'] = data_ads['pt_d'].apply(lambda x: int(str(x)[6:8]))\n",
    "data_ads['hour'] = data_ads['pt_d'].apply(lambda x: int(str(x)[8:10]))\n",
    "# data_ads['minu'] = data_ads['pt_d'].apply(lambda x: int(str(x)[10:12]))\n",
    "# data_ads['date'] = data_ads['day']*1440 + data_ads['hour']*60 + data_ads['minu']\n",
    "\n",
    "\n",
    "def get_date_feature(data, gap_list=[1], col=['user_id']):\n",
    "\n",
    "    for gap in gap_list:\n",
    "\n",
    "        # 后面时间-当前时间\n",
    "        data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
    "        data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] - \\\n",
    "                                                                data['date']\n",
    "\n",
    "        # 前面时间-当前时间\n",
    "        data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
    "        data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data['date'] - data[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)]\n",
    "\n",
    "        # 统计不为nan的值，做差前有曝光，做差后就不会为nan。\n",
    "        data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('count')\n",
    "        data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('count')\n",
    "\n",
    "        # 统计时间差的平均值\n",
    "        data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('mean')\n",
    "        data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('mean')\n",
    "\n",
    "        # 统计时间差的最大值\n",
    "        data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('max')\n",
    "        data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('max')\n",
    "\n",
    "        # 统计时间差的最小值\n",
    "        data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('min')\n",
    "        data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('min')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_diff_date(data, gap_list=[1, 2, 3], col=['user_id'], con_list=[1], f='next'):\n",
    "    for gap in gap_list:\n",
    "        for con in con_list:\n",
    "            data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
    "                'ts_{}_{}_diff_{}'.format('_'.join(col), con, f)].shift(-gap)\n",
    "            data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data['ts_s_{}_{}_{}_next_{}'.format(f,\n",
    "                                                                                                                   '_'.join(\n",
    "                                                                                                                       col),\n",
    "                                                                                                                   gap,\n",
    "                                                                                                                   con)] - \\\n",
    "                                                                               data['ts_{}_{}_diff_{}'.format(\n",
    "                                                                                   '_'.join(col), con, f)]\n",
    "\n",
    "            data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
    "                'ts_{}_{}_diff_{}'.format('_'.join(col), con, f)].shift(+gap)\n",
    "            data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data['ts_{}_{}_diff_{}'.format(\n",
    "                '_'.join(col), con, f)] - data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "for col in [\n",
    "    ['user_id'], ['task_id'], ['adv_id'],\n",
    "    ['user_id', 'adv_id'], ['user_id', 'task_id'], ['user_id', 'creat_type_cd'],\n",
    "    ['user_id', 'adv_prim_id'], ['user_id', 'inter_type_cd'], ['user_id', 'slot_id'],\n",
    "    ['user_id', 'site_id'], ['user_id', 'spread_app_id']\n",
    "]:\n",
    "    print('_'.join(col), 'make', 'feature')\n",
    "    data_ads = get_date_feature(data_ads, gap_list=[1, 2, 3], col=col)\n",
    "    data_ads = get_diff_date(data_ads, gap_list=[1, 2, 3], col=col, con_list=[1], f='next')\n",
    "    data_ads = get_diff_date(data_ads, gap_list=[1, 2, 3], col=col, con_list=[1], f='last')\n",
    "\n",
    "\n",
    "# print('穿越特征 Ending...')\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3、内存压缩\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (\n",
    "                start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "# 压缩使用内存\n",
    "# 由于数据比较大，所以合理的压缩内存节省空间尤为的重要\n",
    "# 使用reduce_mem_usage函数可以压缩近70%的内存占有。\n",
    "data_ads = reduce_mem_usage(data_ads)\n",
    "# Mem. usage decreased to 2351.47 Mb (69.3% reduction)\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------数据集划分-------------\n",
    "# 划分训练集和测试集\n",
    "cols = [f for f in data_ads.columns if f not in ['label', 'istest']]\n",
    "x_train = data_ads[data_ads.istest == 0][cols]\n",
    "x_test = data_ads[data_ads.istest == 1][cols]\n",
    "\n",
    "y_train = data_ads[data_ads.istest == 0]['label']\n",
    "\n",
    "del data_ads, data_feeds\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------训练模型---------------\n",
    "def cv_model(clf, train_x, train_y, test_x, clf_name, seed=2023):\n",
    "    kf = KFold(n_splits=100, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} {}************************************'.format(str(i + 1),\n",
    "                                                                                                      str(seed)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], \\\n",
    "                                     train_y[valid_index]\n",
    "\n",
    "        params = {'random_seed': seed}\n",
    "\n",
    "        model = clf(**params)\n",
    "        model.fit(trn_x, trn_y, eval_set=[(val_x, val_y)],\n",
    "                  verbose=1, eval_metric='auc')\n",
    "\n",
    "        val_pred = model.predict_proba(val_x)[:, 1]\n",
    "        test_pred = model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "        train[valid_index] = val_pred\n",
    "        test += test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "\n",
    "        print(cv_scores)\n",
    "\n",
    "    print(\"%s_score_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "cat_train, cat_test = cv_model(XGBClassifier, x_train, y_train, x_test, \"xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------结果保存---------------\n",
    "x_test['pctr'] = cat_test\n",
    "x_test[['log_id', 'pctr']].to_csv('submission_xgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
